{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Tokens :  579\n"
     ]
    }
   ],
   "source": [
    "base_file = open(\"data/1.txt\", 'rt')\n",
    "raw_text = base_file.read()\n",
    "base_file.close()\n",
    "\n",
    "token_list1 = nltk.word_tokenize(raw_text)\n",
    "token_list2 = [word.replace(\"'\", \"\") for word in token_list1]\n",
    "token_list3 = list(filter(lambda token: nltk.tokenize.punkt.PunktToken(token).is_non_punct, token_list2))\n",
    "token_list4=[word.lower() for word in token_list3]\n",
    "\n",
    "print(\"\\nTotal Tokens : \",len(token_list4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIRST = in ; SECOND = this ; COUNT = 2\n",
      "FIRST = this ; SECOND = practical ; COUNT = 1\n",
      "FIRST = practical ; SECOND = hands-on ; COUNT = 1\n",
      "FIRST = hands-on ; SECOND = course ; COUNT = 1\n",
      "FIRST = course ; SECOND = learn ; COUNT = 1\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\":memory:\")\n",
    "conn.execute('''DROP TABLE IF EXISTS NGRAMS''')\n",
    "conn.execute('''CREATE TABLE NGRAMS \n",
    "         (FIRST   TEXT  NOT NULL,\n",
    "          SECOND  TEXT  NOT NULL,\n",
    "          COUNTS  INT   NOT NULL,\n",
    "         CONSTRAINT PK_GRAMS PRIMARY KEY (FIRST,SECOND));''')\n",
    "\n",
    "for i in ngrams(token_list4,2):\n",
    "    insert_str=\"INSERT INTO NGRAMS (FIRST,SECOND,COUNTS) \\\n",
    "          VALUES ('\" + i[0] + \"','\" + i[1] + \"',1 ) \\\n",
    "          ON CONFLICT(FIRST,SECOND) DO UPDATE SET COUNTS=COUNTS + 1\"   \n",
    "    conn.execute(insert_str);\n",
    "\n",
    "cursor = conn.execute(\"SELECT FIRST, SECOND, COUNTS from NGRAMS LIMIT 5\")\n",
    "for gram_row in cursor:\n",
    "    print(\"FIRST =\", gram_row[0], \"; SECOND =\",gram_row[1],\"; COUNT =\",gram_row[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next word for data : ['science', 'analysis', 'data', 'from', 'in', 'mining', 'munging', 'node.js', 'preparation', 'scientists', 'visualization', 'you']\n",
      "\n",
      "Next word for science : ['begins', 'requires', 'specialists', 'teams']\n"
     ]
    }
   ],
   "source": [
    "def recommend(str):\n",
    "    nextwords = []\n",
    "    cur_filter = conn.execute(\"SELECT SECOND from NGRAMS \\\n",
    "                              WHERE FIRST='\" + str + \"' \\\n",
    "                              ORDER BY COUNTS DESC\")\n",
    "    for filt_row in cur_filter:\n",
    "        nextwords.append(filt_row[0])\n",
    "    return nextwords\n",
    "\n",
    "print(\"Next word for data :\", recommend(\"data\"))\n",
    "print(\"\\nNext word for science :\", recommend(\"science\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
